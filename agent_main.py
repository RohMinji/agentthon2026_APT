from __future__ import annotations

import json
import os
import re
from datetime import datetime

import telebot

from intent_router import classify_intent
from models import AgentRequest, AgentResponse
from orchestrator_core import execute_with_registry
from security_utils import mask_pii
from sub_apartment_recommend_agent import SubApartmentRecommendAgent
from sub_budget_agent import SubBudgetAgent
from sub_buying_plan_manager import SubBuyingPlanManagerAgent
from sub_qa_agent import SubQAAgent
from sub_real_estate_faq_rag_agent import SubRealEstateFaqRagAgent
from sub_real_estate_peak_agent import SubRealEstatePeakAgent

try:
    from dotenv import load_dotenv
except ImportError:  # pragma: no cover
    load_dotenv = None

try:
    from openai import OpenAI
except ImportError:  # pragma: no cover
    OpenAI = None

if load_dotenv is not None:
    load_dotenv()


AGENT_REGISTRY = {
    "apartment_recommend": SubApartmentRecommendAgent(),
    "budget_estimate": SubBudgetAgent(),
    "peak_compare": SubRealEstatePeakAgent(),
    "buying_plan": SubBuyingPlanManagerAgent(),
    "faq_rag": SubRealEstateFaqRagAgent(),
    "qa_report": SubQAAgent(),
}

PENDING_BUYING_CONFIRM: dict[str, AgentRequest] = {}
PENDING_QA_CONFIRM: dict[str, AgentRequest] = {}
LAST_INTENT_TEXT: dict[str, dict[str, str]] = {}
LAST_BOT_REPLY: dict[str, str] = {}
LAST_USER_QUERY: dict[str, str] = {}
USER_CONTEXT_HISTORY: dict[str, list[dict[str, str]]] = {}

TELEGRAM_TOKEN = (os.getenv("TELEGRAM_TOKEN") or "").strip()
if not TELEGRAM_TOKEN:
    raise RuntimeError("TELEGRAM_TOKEN í™˜ê²½ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.")

bot = telebot.TeleBot(TELEGRAM_TOKEN)
DEBUG_CONSOLE_LOG = (os.getenv("DEBUG_CONSOLE_LOG", "1").strip() == "1")


def _is_yes(text: str) -> bool:
    t = text.strip().lower()
    return t in {"ì˜ˆ", "ë„¤", "ì‘", "yes", "y", "ok", "ë³´ë‚´", "ë³´ë‚´ì¤˜"} or "ë³´ë‚´" in t


def _is_no(text: str) -> bool:
    t = text.strip().lower()
    return t in {"ì•„ë‹ˆ", "ì•„ë‹ˆì˜¤", "no", "n", "ì·¨ì†Œ"} or "ì·¨ì†Œ" in t


def _is_followup_confirm(text: str) -> bool:
    t = text.strip().lower()
    tokens = {
        "í™•ì¸í•´ì¤˜",
        "í™•ì¸",
        "ì§„í–‰í•´ì¤˜",
        "ì§„í–‰",
        "ì‘",
        "ë„¤",
        "ê·¸ë˜",
        "ì¢‹ì•„",
        "ì˜¤ì¼€ì´",
        "ok",
        "yes",
    }
    return t in tokens


def _is_peak_followup(text: str) -> bool:
    t = text.strip().lower().replace(" ", "")
    tokens = {
        "ë‹¤ë¥¸í‰í˜•ëŒ€ëŠ”",
        "ë‹¤ë¥¸í‰í˜•ëŒ€",
        "ë‹¤ë¥¸í‰í˜•",
        "ë‹¤ë¥¸í‰ìˆ˜",
        "ë‹¤ë¥¸ë©´ì ",
        "í‰í˜•ë³„ë¡œ",
    }
    return t in tokens or any(tok in t for tok in tokens)


def _is_help_query(text: str) -> bool:
    t = text.strip().lower()
    keywords = [
        "ë­˜í•´ì¤„ìˆ˜ìˆì–´",
        "ë­í•´ì¤„ìˆ˜ìˆì–´",
        "ë­˜í• ìˆ˜ìˆì–´",
        "ë­í• ìˆ˜ìˆì–´",
        "ë¬´ì–¼í• ìˆ˜ìˆì–´",
        "ë¬´ì—‡ì„í• ìˆ˜ìˆì–´",
        "ë„ˆëŠ”ë¬´ì—‡ì„í• ìˆ˜ìˆì–´",
        "ë„ˆëŠ”ë­˜í• ìˆ˜ìˆì–´",
        "ë„ì›€ë§",
        "ì‚¬ìš©ë²•",
        "ë¬´ì—‡ì„ í•  ìˆ˜ ìˆì–´",
        "ë¬´ì—‡ì„í• ìˆ˜ìˆì–´",
        "help",
        "ê°€ëŠ¥í•œ ê¸°ëŠ¥",
        "ê¸°ëŠ¥ ì•Œë ¤",
        "ì–´ë–¤ ê¸°ëŠ¥",
    ]
    normalized = re.sub(r"[^0-9a-zê°€-í£]", "", t.replace(" ", ""))
    return any(k.replace(" ", "") in normalized for k in keywords)


def _help_message() -> str:
    return (
        "ì œê°€ ë„ì™€ë“œë¦´ ìˆ˜ ìˆëŠ” ê¸°ëŠ¥ì…ë‹ˆë‹¤.\n\n"
        "1. ì•„íŒŒíŠ¸ ì¶”ì²œ: ì¡°ê±´(ì§€ì—­/ê°€ê²©/ë©´ì /ë‚œë°©/ì„¸ëŒ€ìˆ˜)ìœ¼ë¡œ ë§¤ë¬¼ íƒìƒ‰\n"
        "2. ì˜ˆì‚° ì¶”ì •: ì›”ì†Œë“/ë³´ìœ ìê¸ˆ ê¸°ë°˜ ëŒ€ëµì  ë§¤ìˆ˜ ì˜ˆì‚° ê³„ì‚°\n"
        "3. ì „ê³ ì  ë¹„êµ: íŠ¹ì • ë‹¨ì§€ì˜ ì „ê³ ì  ëŒ€ë¹„ í˜„ì¬ê°€ í™•ì¸\n"
        "4. ë§¤ë§¤ ì¼ì • ì •ë¦¬: ê³„ì•½ì¼/ì”ê¸ˆì¼ ê¸°ì¤€ í•„ìˆ˜Â·ê¶Œì¥ ì¼ì • ìƒì„±\n"
        "5. ì •ì±… FAQ: PDF ê·¼ê±° ê¸°ë°˜ìœ¼ë¡œ ì •ì±… ì§ˆì˜ ì‘ë‹µ\n"
        "6. QA ë¦¬í¬íŠ¸: ë¯¼ê°ì •ë³´ ë§ˆìŠ¤í‚¹ ë° QA ë¦¬í¬íŠ¸ ì²˜ë¦¬\n\n"
        "ì˜ˆì‹œ ì§ˆë¬¸\n"
        "- ì†¡íŒŒêµ¬ 15ì–µ ì´í•˜ 84ã¡ ì•„íŒŒíŠ¸ ì¶”ì²œí•´ì¤˜\n"
        "- ì›”ì†Œë“ 500, ë³´ìœ ìê¸ˆ 2ì–µì´ë©´ ì˜ˆì‚° ì–¼ë§ˆë‚˜ ë¼?\n"
        "- ì ì‹¤ ë¦¬ì„¼ì¸  ì „ê³ ì  ëŒ€ë¹„ í˜„ì¬ê°€ ì•Œë ¤ì¤˜\n"
        "- ê³„ì•½ì¼ 2026-05-10, ì”ê¸ˆì¼ 2026-07-01 ì¼ì • ì •ë¦¬í•´ì¤˜\n"
        "- ì·¨ë“ì„¸ ì‹ ê³  ê¸°í•œì„ ì •ì±… ë¬¸ì„œ ê·¼ê±°ë¡œ ì•Œë ¤ì¤˜"
    )


def execute_request(req: AgentRequest, intent: str | None = None) -> AgentResponse:
    return execute_with_registry(
        req,
        AGENT_REGISTRY,
        intent_override=intent,
        enabled_capabilities=None,
        user_role=os.getenv("DEFAULT_USER_ROLE", "user"),
        audit_log_path=os.getenv("AUDIT_LOG_PATH", "audit_log.jsonl"),
    )


def _clear_user_state(user_id: str) -> None:
    PENDING_BUYING_CONFIRM.pop(user_id, None)
    PENDING_QA_CONFIRM.pop(user_id, None)
    LAST_INTENT_TEXT.pop(user_id, None)
    LAST_BOT_REPLY.pop(user_id, None)
    LAST_USER_QUERY.pop(user_id, None)
    USER_CONTEXT_HISTORY.pop(user_id, None)


def _reply_with_waiting(chat_id: int, build_reply, waiting_text: str = "ğŸ¤– AIê°€ ìƒê° ì¤‘ì…ë‹ˆë‹¤...") -> None:
    bot.send_chat_action(chat_id, "typing")
    waiting_msg = bot.send_message(chat_id, waiting_text)
    try:
        reply_text = build_reply()
        bot.edit_message_text(chat_id=chat_id, message_id=waiting_msg.message_id, text=reply_text)
    except Exception as e:
        bot.edit_message_text(chat_id=chat_id, message_id=waiting_msg.message_id, text=f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")


def _has_intent_keyword(text: str, intent: str) -> bool:
    t = (text or "").lower()
    if intent == "qa_report":
        qa_keys = ["qa ë¦¬í¬íŠ¸", "qaë¦¬í¬íŠ¸", "qa í‰ê°€", "qaí‰ê°€", "qa ì ê²€", "qaì ê²€", "quality report"]
        if any(k in t for k in qa_keys):
            return True
        tokens = t.replace("/", " ").replace("-", " ").split()
        return "qa" in tokens

    mapping = {
        "buying_plan": ["ê³„ì•½ì¼", "ì”ê¸ˆì¼", "ì·¨ë“ì„¸", "ë“±ê¸°", "ì…ì£¼", "ì „ì…"],
        "peak_compare": ["ì „ê³ ì ", "í˜„ì¬ê°€ ë¹„êµ", "ìµœê³ ê°€"],
        "budget_estimate": ["ì˜ˆì‚°", "ì›”ì†Œë“", "ëŒ€ì¶œ", "dsr"],
        "faq_rag": ["ì •ì±…", "faq", "pdf", "ê·¼ê±°", "ì¶œì²˜"],
    }
    return any(k in t for k in mapping.get(intent, []))


def _detect_intent(text: str) -> tuple[str, bool]:
    """
    GPT intent + rule intent êµì°¨ê²€ì¦.
    ë¶ˆì¼ì¹˜í•˜ê³  ì‹ í˜¸ê°€ ì•½í•˜ë©´ uncertain=Trueë¡œ ë°˜í™˜í•œë‹¤.
    """
    gpt_intent = _classify_intent_with_gpt(text)
    rule_intent = classify_intent(text)

    if not gpt_intent:
        return rule_intent, False
    if gpt_intent == rule_intent:
        return gpt_intent, False

    # GPTê°€ íŠ¹ìˆ˜ intentë¥¼ ê°•í•˜ê²Œ ì£¼ì¥í•˜ì§€ë§Œ í‚¤ì›Œë“œ ê·¼ê±°ê°€ ì—†ìœ¼ë©´ ë¶ˆí™•ì‹¤ ì²˜ë¦¬
    if gpt_intent in {"qa_report", "buying_plan", "peak_compare", "budget_estimate", "faq_rag"}:
        if not _has_intent_keyword(text, gpt_intent):
            return rule_intent, True

    return gpt_intent, False


def _classify_intent_with_gpt(text: str) -> str | None:
    if OpenAI is None:
        return None

    api_key = (os.getenv("AZURE_OPENAI_API_KEY") or "").strip()
    endpoint = (os.getenv("AZURE_OPENAI_ENDPOINT") or "").strip().rstrip("/")
    model = (os.getenv("AZURE_OPENAI_CHAT_DEPLOYMENT_NAME") or "gpt-4o").strip()
    if not (api_key and endpoint):
        return None

    try:
        client = OpenAI(base_url=f"{endpoint}/openai/v1/", api_key=api_key)
        schema = {
            "type": "object",
            "properties": {
                "intent": {
                    "type": "string",
                    "enum": [
                        "apartment_recommend",
                        "budget_estimate",
                        "peak_compare",
                        "buying_plan",
                        "faq_rag",
                        "qa_report",
                    ],
                }
            },
            "required": ["intent"],
            "additionalProperties": False,
        }
        completion = client.chat.completions.create(
            model=model,
            messages=[
                {
                    "role": "system",
                    "content": (
                        "ë„ˆëŠ” ë¶€ë™ì‚° ë©€í‹°ì—ì´ì „íŠ¸ ë¼ìš°í„°ë‹¤. ì‚¬ìš©ì ë¬¸ì¥ì„ ì•„ë˜ intent ì¤‘ í•˜ë‚˜ë¡œë§Œ ë¶„ë¥˜í•˜ë¼. "
                        "ë°˜ë“œì‹œ JSONë§Œ ì¶œë ¥í•œë‹¤."
                    ),
                },
                {"role": "user", "content": text},
            ],
            response_format={
                "type": "json_schema",
                "json_schema": {"name": "intent_router", "strict": True, "schema": schema},
            },
            temperature=0,
        )
        payload = json.loads(completion.choices[0].message.content)
        intent = payload.get("intent")
        if intent in AGENT_REGISTRY:
            return intent
    except Exception:
        return None
    return None


def _extract_household_suggestion(reply_text: str) -> str:
    m = re.search(r"(\\d{2,5})\\s*ì„¸ëŒ€\\s*ì´ìƒ", reply_text or "")
    if not m:
        return ""
    return f"{m.group(1)}ì„¸ëŒ€ ì´ìƒ"


def _looks_like_pii_mask_test(text: str) -> bool:
    t = (text or "").lower()
    markers = [
        "[phone_masked]",
        "[email_masked]",
        "[rrn_masked]",
        "[account_masked]",
        "ì—°ë½ì²˜",
        "ì£¼ë¯¼ë²ˆí˜¸",
        "ê³„ì¢Œ",
        "ì´ë©”ì¼",
    ]
    return any(m in t for m in markers)


def _append_context_history(user_id: str, user_text: str, intent: str, bot_text: str) -> None:
    history = USER_CONTEXT_HISTORY.setdefault(user_id, [])
    history.append(
        {
            "timestamp": datetime.now().isoformat(timespec="seconds"),
            "intent": intent,
            "user": user_text,
            "bot": bot_text,
        }
    )


@bot.message_handler(commands=["new", "reset"])
def reset_cmd(message):
    user_id = str(message.from_user.id)
    _clear_user_state(user_id)
    apt_agent = AGENT_REGISTRY.get("apartment_recommend")
    if apt_agent and hasattr(apt_agent, "reset_user_session"):
        try:
            apt_agent.reset_user_session(user_id)
        except Exception:
            pass
    bot.send_message(message.chat.id, "ìƒíƒœë¥¼ ì´ˆê¸°í™”í–ˆìŠµë‹ˆë‹¤.")


@bot.message_handler(func=lambda m: True)
def handle_message(message):
    user_id = str(message.from_user.id)
    text = (message.text or "").strip()
    if not text:
        bot.send_message(message.chat.id, "ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        return

    if _is_help_query(text):
        msg = _help_message()
        LAST_BOT_REPLY[user_id] = msg
        _append_context_history(user_id, text, "help", msg)
        if DEBUG_CONSOLE_LOG:
            print(f"[USER:{user_id}] {mask_pii(text)}\n[INTENT] help\n[BOT] {mask_pii(msg)}\n")
        bot.send_message(message.chat.id, msg)
        return

    pending = PENDING_BUYING_CONFIRM.get(user_id)
    if pending is not None:
        if _is_yes(text):
            pending.metadata["confirm_send"] = True
            def _on_confirm_yes() -> str:
                resp = execute_request(pending, intent="buying_plan")
                PENDING_BUYING_CONFIRM.pop(user_id, None)
                _log_exchange(user_id, pending.text, "buying_plan", resp)
                msg = _format_for_telegram(resp)
                LAST_BOT_REPLY[user_id] = msg
                _append_context_history(user_id, pending.text, "buying_plan", msg)
                return msg

            _reply_with_waiting(message.chat.id, _on_confirm_yes)
            return
        if _is_no(text):
            PENDING_BUYING_CONFIRM.pop(user_id, None)
            cancel_msg = "ë©”ì¼ ë°œì†¡ì„ ì·¨ì†Œí–ˆìŠµë‹ˆë‹¤."
            _append_context_history(user_id, text, "buying_plan", cancel_msg)
            bot.send_message(message.chat.id, cancel_msg)
            return
        guide_msg = "ë©”ì¼ ë°œì†¡ ì—¬ë¶€ë¥¼ 'ì˜ˆ/ì•„ë‹ˆì˜¤'ë¡œ ë‹µí•´ì£¼ì„¸ìš”."
        _append_context_history(user_id, text, "buying_plan", guide_msg)
        bot.send_message(message.chat.id, guide_msg)
        return

    pending_qa = PENDING_QA_CONFIRM.get(user_id)
    if pending_qa is not None:
        if _is_yes(text):
            pending_qa.metadata["send_mail"] = True
            if not pending_qa.metadata.get("assistant_answer"):
                pending_qa.metadata["assistant_answer"] = LAST_BOT_REPLY.get(user_id, "")

            def _on_qa_confirm_yes() -> str:
                resp = execute_request(pending_qa, intent="qa_report")
                PENDING_QA_CONFIRM.pop(user_id, None)
                _log_exchange(user_id, pending_qa.text, "qa_report", resp)
                msg = _format_for_telegram(resp)
                LAST_BOT_REPLY[user_id] = msg
                _append_context_history(user_id, pending_qa.text, "qa_report", msg)
                return msg

            _reply_with_waiting(message.chat.id, _on_qa_confirm_yes)
            return
        if _is_no(text):
            PENDING_QA_CONFIRM.pop(user_id, None)
            cancel_msg = "QA ë¦¬í¬íŠ¸ ë©”ì¼ ë°œì†¡ì„ ì·¨ì†Œí–ˆìŠµë‹ˆë‹¤."
            _append_context_history(user_id, text, "qa_report", cancel_msg)
            bot.send_message(message.chat.id, cancel_msg)
            return
        guide_msg = "QA ë¦¬í¬íŠ¸ ë©”ì¼ ë°œì†¡ ì—¬ë¶€ë¥¼ 'ì˜ˆ/ì•„ë‹ˆì˜¤'ë¡œ ë‹µí•´ì£¼ì„¸ìš”."
        _append_context_history(user_id, text, "qa_report", guide_msg)
        bot.send_message(message.chat.id, guide_msg)
        return

    req = AgentRequest(user_id=user_id, text=text)
    intent, uncertain_intent = _detect_intent(text)

    # í•˜ë“œ ê°€ë“œ: ê°œì¸ì •ë³´/ë§ˆìŠ¤í‚¹ í…ŒìŠ¤íŠ¸ ë¬¸ì¥ì€ QA ë¦¬í¬íŠ¸ë¡œ ë³´ë‚´ì§€ ì•ŠìŒ
    if _looks_like_pii_mask_test(text) and not _has_intent_keyword(text, "qa_report"):
        uncertain_intent = True

    # í•˜ë“œ ê°€ë“œ: QA ë¦¬í¬íŠ¸ëŠ” ëª…ì‹œ í‚¤ì›Œë“œê°€ ìˆì„ ë•Œë§Œ í—ˆìš©
    if intent == "qa_report" and not _has_intent_keyword(text, "qa_report"):
        uncertain_intent = True

    if uncertain_intent:
        clarify = (
            "ìš”ì²­ ì˜ë„ë¥¼ ì •í™•íˆ íŒŒì•…í•˜ê¸° ì–´ë ¤ì›Œì„œ í™•ì¸ì´ í•„ìš”í•´ìš”.\n"
            "ì•„ë˜ ì¤‘ ì›í•˜ëŠ” ì‘ì—…ì„ ì§§ê²Œ ì•Œë ¤ì£¼ì„¸ìš”.\n"
            "- ì•„íŒŒíŠ¸ ì¶”ì²œ\n"
            "- ì „ê³ ì  ë¹„êµ\n"
            "- ë§¤ë§¤ ì¼ì • ìƒì„±\n"
            "- ì •ì±… FAQ\n"
            "- QA ë¦¬í¬íŠ¸"
        )
        LAST_BOT_REPLY[user_id] = clarify
        _append_context_history(user_id, text, "uncertain", clarify)
        if DEBUG_CONSOLE_LOG:
            print(f"[USER:{user_id}] {mask_pii(text)}\n[INTENT] uncertain\n[BOT] {mask_pii(clarify)}\n")
        bot.send_message(message.chat.id, clarify)
        return

    # "ë‹¤ë¥¸ í‰í˜•ëŒ€ëŠ”?" ê°™ì€ í›„ì† ì§ˆë¬¸ì€ intentê°€ í”ë“¤ë ¤ë„ peak_compareë¡œ ê°•ì œ ì—°ê²°
    if _is_peak_followup(text):
        prev_peak = LAST_INTENT_TEXT.get(user_id, {}).get("peak_compare")
        if prev_peak:
            intent = "peak_compare"
            req.text = prev_peak + " ë‹¤ë¥¸ í‰í˜•ëŒ€"

    if intent == "apartment_recommend" and _is_followup_confirm(text):
        prev = LAST_INTENT_TEXT.get(user_id, {}).get("apartment_recommend")
        if prev:
            addon = _extract_household_suggestion(LAST_BOT_REPLY.get(user_id, ""))
            req.text = f"{prev} {addon}".strip()

    if intent == "buying_plan":
        def _on_buying_plan() -> str:
            req.metadata["confirm_send"] = False
            resp = execute_request(req, intent=intent)
            if resp.success:
                _log_exchange(user_id, text, intent, resp)
                PENDING_BUYING_CONFIRM[user_id] = req
                msg = _format_for_telegram(resp) + "\n\në©”ì¼ë¡œ ë³´ë‚´ë“œë¦´ê¹Œìš”? (ì˜ˆ/ì•„ë‹ˆì˜¤)"
                LAST_BOT_REPLY[user_id] = msg
                return msg
            msg = _format_for_telegram(resp)
            LAST_BOT_REPLY[user_id] = msg
            return msg

        _reply_with_waiting(message.chat.id, _on_buying_plan)
        return

    if intent == "qa_report":
        wants_send = ("ë³´ë‚´" in text) or ("ë©”ì¼" in text) or ("send" in text.lower())
        req.metadata["send_mail"] = wants_send
        req.metadata["assistant_answer"] = LAST_BOT_REPLY.get(user_id, "")
        req.metadata["target_question"] = LAST_USER_QUERY.get(user_id, text)
        req.metadata["context_history"] = USER_CONTEXT_HISTORY.get(user_id, [])

        def _on_qa() -> str:
            resp = execute_request(req, intent=intent)
            _log_exchange(user_id, text, intent, resp)
            msg = _format_for_telegram(resp)
            if resp.success and not wants_send:
                PENDING_QA_CONFIRM[user_id] = AgentRequest(
                    user_id=req.user_id,
                    text=req.text,
                    timezone=req.timezone,
                    metadata={
                        "send_mail": False,
                        "assistant_answer": LAST_BOT_REPLY.get(user_id, ""),
                        "target_question": LAST_USER_QUERY.get(user_id, text),
                        "context_history": USER_CONTEXT_HISTORY.get(user_id, []),
                    },
                    attachments=req.attachments,
                )
                msg = msg + "\n\nQA ë¦¬í¬íŠ¸ë¥¼ ë©”ì¼ë¡œë„ ë³´ë‚´ë“œë¦´ê¹Œìš”? (ì˜ˆ/ì•„ë‹ˆì˜¤)"
            LAST_BOT_REPLY[user_id] = msg
            _append_context_history(user_id, text, intent, msg)
            return msg

        _reply_with_waiting(message.chat.id, _on_qa, waiting_text="ë¦¬í¬íŠ¸ë¥¼ ìƒì„±ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”")
        return

    def _on_general() -> str:
        resp = execute_request(req, intent=intent)
        if intent == "apartment_recommend" and not _is_followup_confirm(text):
            LAST_INTENT_TEXT.setdefault(user_id, {})["apartment_recommend"] = text
        if intent == "peak_compare" and not _is_peak_followup(text):
            LAST_INTENT_TEXT.setdefault(user_id, {})["peak_compare"] = req.text
        _log_exchange(user_id, text, intent, resp)
        msg = _format_for_telegram(resp)
        LAST_BOT_REPLY[user_id] = msg
        _append_context_history(user_id, text, intent, msg)
        if intent != "qa_report":
            LAST_USER_QUERY[user_id] = text
        return msg

    _reply_with_waiting(message.chat.id, _on_general)


def _format_for_telegram(resp: AgentResponse) -> str:
    lines = [resp.message]
    if resp.errors:
        lines.append("")
        lines.append("[errors]")
        for e in resp.errors:
            lines.append(f"- {e}")
    return "\n".join(lines)


def _log_exchange(user_id: str, user_text: str, intent: str, resp: AgentResponse) -> None:
    if not DEBUG_CONSOLE_LOG:
        return
    safe_user_text = mask_pii(user_text)
    safe_reply = mask_pii(resp.message)
    print(
        f"[USER:{user_id}] {safe_user_text}\n"
        f"[INTENT] {intent}\n"
        f"[BOT] {safe_reply}\n"
    )


if __name__ == "__main__":
    print("APT ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¤‘...")
    bot.infinity_polling()
